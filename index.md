---
layout: page
title:
permalink: /

pubs:

    - title:   "A Bayesian Account of Measures of Interpretability in Human-AI Interaction"
      author:  "S. Sreedharan, A. Kulkarni, T. Chakraborti, D. Smith, & S. Kambhampati"
      journal: "in Proceedings of Workshop on Cooperative AI at Conference on Neural Information Processing Systems (NeurIPS), 2020, also appeared in the Workshop on Explainable AI Planning at International Conference on Automated Planning and Scheduling (ICAPS) 2020."
      url:     "https://drive.google.com/file/d/1LXnjS_O0u1B3egUyiz6wtaHJ-lC6YOdF/view"
    
    - title:   "Designing Environments Conducive to Interpretable Robot Behavior"
      author:  "A. Kulkarni*, S. Sreedharan*, S. Keren, T. Chakraborti, D. Smith, & S. Kambhampati"
      journal: "in Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) 2020."
      url:     "https://yochan-lab.github.io/papers/files/papers/IROS2020_design_for_explicability.pdf"

    - title:   "Signaling Friends and Head-Faking Enemies Simultaneously: Balancing Goal Obfuscation and Goal Legibility"
      author:  "A. Kulkarni, S. Srivastava, & S. Kambhampati"
      journal: "as an Extended Abstract in Proceedings of International Conference on Autonomous Agents and Multiagent Systems (AAMAS) 2020."
      url:     "https://arxiv.org/pdf/1905.10672.pdf"

    - title:   "Explicability? Legibility? Predictability? Transparency? Privacy? Security? The Emerging Landscape of Interpretable Agent Behavior"
      author:  "T. Chakraborti, A. Kulkarni, S. Sreedharan, D. Smith, & S. Kambhampati"
      journal: "in Proceedings of International Conference on Automated Planning and Scheduling (ICAPS) 2019."
      url:     "https://arxiv.org/pdf/1811.09722.pdf"

    - title:   "Design for Interpretability"
      author:  "A. Kulkarni*, S. Sreedharan*, S. Keren, T. Chakraborti, D. Smith, & S. Kambhampati"
      journal: "in Proceedings of Workshop on Explainable AI Planning at International Conference on Automated Planning and Scheduling (ICAPS) 2019."
      url:     "https://openreview.net/forum?id=rkxg4a3m9N"

    - title:   "Explicability as Minimizing Distance from Expected Behavior"
      author:  "A. Kulkarni, Y. Zha, T. Chakraborti, S. Vadlamudi, Y. Zhang, & S. Kambhampati"
      journal: "as an Extended Abstract in Proceedings of International Conference on Autonomous Agents and Multiagent Systems (AAMAS) 2019."
      url:     "https://arxiv.org/pdf/1611.05497.pdf"
  
    - title:   "A Unified Framework for Planning in Adversarial and Cooperative Environments"
      author:  "A. Kulkarni, S. Srivastava, & S. Kambhampati"
      journal: "in Proceedings of AAAI 2019, also appeared in the International Conference on Automated Planning and Scheduling (ICAPS) 2018 Workshop on Planning and Robotics."
      url:     "https://yochan-lab.github.io/papers/files/papers/anagha-aaai-2019.pdf"
      media:
        - name: "YouTube"
          url:  "https://youtu.be/9eteZS5Vw84"
    
    - title:   "Resource Bounded Secure Goal Obfuscation"
      author:  "A. Kulkarni, M. Klenk, S. Rane, & H. Souroush"
      journal: "appeared in the AAAI 2018 Fall Symposium on Integrating Planning, Diagnosis and Causal Reasoning, and in AAAI 2019 Workshop on Plan, Activity and Intent Recognition."
      url:     "http://www.public.asu.edu/~akulka16/papers/parc-obfuscation-aaai.pdf"
      
    - title:   "Projection-Aware Task Planning and Execution for Human-in-the-Loop Operation of Robots in a Mixed-Reality Workspace"
      author:  "T. Chakraborti, S. Sreedharan, A. Kulkarni, & S. Kambhampati"
      journal: "in Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) 2018, also appeared in HRI 2018 Workshop on Virtual, Augmented and Mixed Reality for Human-Robot Interaction, and in ICAPS 2018 Workshop on User Interfaces & Scheduling & Planning."
      url:     "https://yochan-lab.github.io/papers/files/papers/projection-aware.pdf"
      media:
        - name: "YouTube"
          url:  "https://www.dropbox.com/s/qmvme1f2duk3jmm/final_iros.mp4"

    - title:   "Explicability as Minimizing Distance from Expected Behavior"
      author:  "A. Kulkarni, Y. Zha, T. Chakraborti, S. Vadlamudi, Y. Zhang, & S. Kambhampati"
      journal: "in the International Conference on Automated Planning and Scheduling (ICAPS) 2018 Workshop on Explainable AI Planning."
      url:     "https://arxiv.org/pdf/1611.05497.pdf"
      media:
        - name: "YouTube"
          url:  "https://youtu.be/iLG-ANQtYms"

    - title:   "Augmented Workspace for Human-in-the-Loop Plan Execution"
      author:  "T. Chakraborti, S. Sreedharan, A. Kulkarni, & S. Kambhampati"
      journal: "in ICAPS 2017 Workshop on User Interfaces & Scheduling & Planning; and ICAPS 2017 System Demonstrations and Exhibits."
      url:     "https://arxiv.org/pdf/1703.08930.pdf"
      media:
        - name: "YouTube"
          url:  "https://youtu.be/K3uWkos6q1g"
        - name: "U.S. Microsoft Imagine Cup 2017 Finalist"
          url:  "https://youtu.be/ps1xUEHpTEA"
        - name: "PBS 8 Cronkite News"
          url:  "https://youtu.be/CFAZSgn_8i0"
        - name: "ASU Fulton School News"
          url:  "https://fullcircle.asu.edu/students/asu-team-taking-concept-closer-human-robot-connection-u-s-imagine-cup-finals/"
        - name: "ACM Tech News"
          url:  "https://technews.acm.org/archives.cfm?fo=2017-04-apr/apr-17-2017.html"

    - title:   "Plan Explicability and Predictability for Robot Task Planning"
      author:  "Y. Zhang, S. Sreedharan, A. Kulkarni, T. Chakraborti, H. H. Zhuo, & S. Kambhampati"
      journal: "in Proceedings of the IEEE International Conference on Robotics and Automation (ICRA) 2017, and also appeared in Robotics: Science and Systems (RSS) 2016 Workshop on Planning for Human-Robot Interaction: Shared Autonomy and Collaborative Robotics."
      url:     "http://rakaposhi.eas.asu.edu/icra17-explicability.pdf"
      media:
        - name: "YouTube"
          url:  "https://youtu.be/AAAwSVbAV7s"

    - title:   "Explicable Plans for Human-Robot Teams"
      author:  "A. Kulkarni"
      journal: "in AIJ Student Spotlight, Robotics: Science and Systems (RSS) 2016 Workshop on Planning for Human-Robot Interaction: Shared Autonomy and Collaborative Robotics."
      url:     "http://people.csail.mit.edu/cdarpino/RSS2016WorkshopHRcolla/abstracts/RSS16WS_AI_award_ExplicablePlans.pdf"
      media:
        - name: "YouTube"
          url:  "https://youtu.be/EjuK9YDDJkA"

---

{% include image.html url="images/anagha.jpg" caption="" max_width="3.5px" align="right" %}

I am now an AI Scientist at [Invitae](https://www.invitae.com/en){:target="_blank"}. 

I received my Ph.D. in Computer Science from [Arizona State University](http://www.asu.edu){:target="_blank"}. At ASU, I was a member of [Yochan](https://yochan-lab.github.io/home/){:target="_blank"} research group directed by [Prof. Subbarao Kambhampati](http://rakaposhi.eas.asu.edu/){:target="_blank"}. My Ph.D. thesis outlines how an AI agent can reason over the human’s mental model of itself to synthesize human-aware AI behaviors and establishes a taxonomy of different types of interpretable as well as obfuscatory AI behaviors. 

Before joining ASU in 2015, I completed my M.S. in Computer Science at [University of Southern California](http://www.usc.edu){:target="_blank"}. At USC, I worked with [Dr. T. K. Satish Kumar](https://www.tkskwork.org/){:target="_blank"} on multi-agent path planning problems.

If you'd like to contact me, please drop me a [mail](mailto:kulkarni.p.anagha@gmail.com) or find me on [LinkedIn](https://www.linkedin.com/in/anaghapk){:target="_blank"}.

# Research
* Interests: Human-aware AI Planning, Explainable AI, Privacy Preserving AI
* Overview of my research &nbsp;&nbsp;&nbsp;&nbsp; [[Poster]](https://www.dropbox.com/s/zxo80tsqxl40t5t/ResearchPoster.pdf?dl=0) &nbsp;&nbsp;&nbsp;&nbsp; [[Video]](https://youtu.be/WvjNAWtnCbs)
* AAAI 2020 Tutorial on Synthesizing Explainable and Deceptive Behavior for Human-AI Interaction
[[Tutorial slide deck]](https://www.dropbox.com/s/9z9iedehwhcxm22/tutorial.pdf?dl=0) &nbsp;&nbsp;&nbsp;&nbsp; [[Tutorial overview, Contents, Video]](https://yochan-lab.github.io/tutorial/AAAI-2020/)

# <a name="thesis"></a>Thesis

### Synthesis of Interpretable and Obfuscatory Behaviors in Human-Aware AI Systems 
[[Dissertation]](/files/thesis.pdf){:target="_blank"}  &nbsp;&nbsp;&nbsp;&nbsp; [[Video]](https://www.youtube.com/watch?v=j--M3l6412Q){:target="_blank"}

### Advisor
  
  [Subbarao Kambhampati](http://rakaposhi.eas.asu.edu/){:target="_blank"} | Arizona State University

### Committee Members
  
  [Ece Kamar](https://www.ecekamar.com/){:target="_blank"} | Microsoft Research 
  [David E. Smith](http://psresearch.xyz/){:target="_blank"} | (Retired) NASA Ames Research Center
  [Siddharth Srivastava](http://siddharthsrivastava.net/){:target="_blank"} | Arizona State University
  [Yu Zhang](http://www.public.asu.edu/~yzhan442/){:target="_blank"} | Arizona State University

### Abstract 

In settings where a human and an AI agent coexist, the agent has to be capable of reasoning with the human’s preconceived notions about the environment as well as with the human’s perception limitations. In addition, it should be capable of communicating intentions and objectives effectively to the human-in- the-loop. When an embodied AI agent acts in the presence of human observers, it can synthesize interpretable behaviors like explicable, legible, and assistive behaviors by accounting for the human’s mental model (inclusive of her sensor model) in its reasoning process. This thesis will study different behavior synthesis algorithms which focus on improving the interpretability of the agent’s behavior in the presence of a human observer. Further, this thesis will study how environment redesign strategies can be leveraged to improve the overall interpretability of the agent’s behavior. At times, the agent’s environment may also consist of purely adversarial entities or mixed entities (i.e. adversarial as well as cooperative entities), that are trying to infer information from the AI agent’s behavior. In such settings, it is crucial for the agent to exhibit obfuscatory behavior that prevents sensitive information from falling into the hands of the adversarial entities. This thesis will show that it is possible to synthesize interpretable as well as obfuscatory behaviors using a single underlying algorithmic framework.

# <a name="publications"></a>Publications 

{% for pub in page.pubs %}
[**{{pub.title}}**]({% if pub.internal %}{{pub.url | prepend: site.baseurl}}{% else %}{{pub.url}}{% endif %}){:target="_blank"}<br />
{{pub.author}}<br />
*{{pub.journal}}*
{% if pub.media %}<br />Media: {% for article in pub.media %}[[{{article.name}}]({{article.url}}){:target="_blank"}] {% endfor %}{% endif %}
{% endfor %}

